\section*{Appendix 1: Horrock's Theorem}

We present a constructive proof of the the following special case of the {\em affine}
Horrocks Theorem \cite{Lam}, V.2, for a commutative ring $A$. We
essentially follow Nashier-Nichols' Proof of Horrocks Theorem, as presented in \cite{Lam}, IV.5.
(Another constructive proof can be found in \cite{lombardi-quitte}, XVI.4).

\begin{lemma}\label{Horrocks}
  If an ideal of $A[X]$ divides a principal ideal $(f)$ with $f$ monic then it is itself a principal ideal.
\end{lemma}

Let $L$ and $M$ be such that $L\cdot M = (f)$. We can then write $f = \Sigma u_iv_i$ with $u_i$ in $L$ and
$v_i$ in $M$. Using $f$ monic, we then have $L = (u_1,\dots,u_n)$ and $M = (v_1,\dots,v_n)$.
The strategy of the proof is to build comaximal monoids $S_1,\dots,S_l$ in $A$ \cite{lombardi-quitte},
XIV.1, such that $L$ is generated by a monic polynomial in each $A_{S_j}[X]$.

\subsection{Formal computation of gcd}

%We start by describing a general technique introduced in \cite{lombardi-quitte}.

 If we have a list $u_1,\dots,u_n$ of polynomials over a field we can compute the gcd of this list
$(g) = (u_1,\dots,u_n)$ and $g$ is either $0$ (in the case where all the polynomials $u_1,\dots,u_n$ are $0$)
 or a monic polynomial. More generally, over a local ring $A$ which is residually discrete of maximal
 ideal $m$, we can compute a polynomial $g$ in $A[X]$ such that 
 $(g) = (u_1,\dots,u_n)$ modulo $m$
 and $g$ is either $0$ (in the case where all the polynomials $u_1,\dots,u_n$ are $0$ modulo $m$)
 or a monic polynomial.

In general, if we are over an arbitrary ring $A$, we can interpret this computation formally as
follows (\cite{lombardi-quitte}, XIV.1). We build a binary tree of root $A$, where at each node,
we intuitively force an element of $A$ to be in the Jacobson radical
or to be invertible modulo this ideal.
To each node is associated a pair of finite sets $I;U$
of elements in $A$ and we associate the monoid $S(I;U) = M(U) + (I)$ where $M(U)$ is the multiplicative
monoid generated by $U$ and $(I)$ the ideal generated by $I$.

Corresponding to the formal computation of the gcd, we get a binary tree where we have at each leaf
a ring $A_{S(I;U)}$ and a polynomial $g$ in $A_{S(I;U)}[X]$, which is monic or $0$, and
such that $(g) = (u_1,\dots,u_n)$ modulo the ideal generated by $I$ in $A_{S(I;U)}$.

%% We have assumed that the ideal $(u_1,\dots,u_n)$ in $A[X]$
%% contains a monic polynomial, so we can only have $g = 0$ if $1=0$ in $A(I;U)$ and we can replace
%% $g$ by $1$. So in the case where the ideal $(u_1,\dots,u_n)$ in $A[X]$ contains a monic
%% polynomial, we can assume that on each leach we have a {\em monic} polynomial.

%% Like in \cite{lombardi-quitte}, XIV.1, we can also associate to each branch
%% the multiplicative monoid $S(I;U) = M(U) + (I)$.
%% In the ring $A_{S(I;U)}$ we force the elements in $U$ to be invertible {\em and} the elements
%% in $I$ to be in the Jacobson radical \cite{lombardi-quitte}.
If we do this for each branch, we get a list of monoids $S_1,\dots,S_l$
that are {\em comaximal} (\cite{lombardi-quitte}, XIV.1): if $s_i$ in $S_i$ then $1 = (s_1,\dots,s_l)$.

\subsection{Application to Horrocks' Theorem}

We assume that $(u_1,\dots,u_n)$ divides $(f)$, with $f$ monic.
The goal is to build comaximal monoids $S_1,\dots,S_l$ with $(u_1,\dots,u_n)$ principal
and generated by a monic polynomial in $A_{S_j}[X]$.

Note that $(u_1,\dots,u_n)$ contains the monic polynomial $f$.

We first build a binary tree which corresponds to the formal computation of the gcd of
$u_1,\dots,u_n$ as described above. For each branch $I;U$ we have a monic polynomial
$g$ in $A_{S(I;U)}[X]$, which belongs to $(u_1,\dots,u_n)$, and
such that $(u_1,\dots,u_n) = (g)$ modulo\footnote{Since $(u_1,\dots,u_n)$
contains a monic polynomial, the case where $g=0$ can only happen if $0$ belongs to in $S(I;U)$ and in this
case, we can replace $g$ by $1$.} the ideal generated by $I$.

The next Lemma is Lemma IV.5.1, \cite{Lam} in Lam's presentation of
Nashier-Nichols' Proof of Horrocks Theorem.

\begin{lemma}
  Let $R$ be a ring with an ideal $J$ contained in the Jacobson radical
  and $L$ an ideal of $R[X]$ which contains a monic polynomial. We consider
  the reduction modulo $J$
  $$\pi: R[X]\mapsto (R/J)[X]$$
  Any monic polynomial of $\pi(L)$ can be lifted to a monic polynomial in $L$.
\end{lemma}

 Using this Lemma, we get a monic polynomial $h$ in $(u_1,\dots,u_n)$ in $A_{S(I;U)}[X]$
 and such that $h$ generates $(u_1,\dots,u_n)$ modulo $(I)$.
 We can now use that $I$ is contained in the Jacobson radical of $A_{S(I;U)}$ and the
 following second Lemma, which corresponds to Proposition IV.5.2 of \cite{Lam},
 to conclude that we actually have $(h) = (u_1,\dots,u_n)$ in $A_{S(I;U)}[X]$.

\begin{lemma}
  Let $R$ a ring, $J$ an ideal of $R$ contained in the Jacobson radical of $R$. If
  we have $L\cdot M = (f)$ with $f$ monic in $R[X]$, and $L$ contains a monic polynomial
  $h$ such that $L = (h)$ in $(R/J)[X]$ then $L = (h)$ in $R[X]$.
\end{lemma}

\begin{proof}
  Since $L$ contains $L\cap J$ and $L\cdot M = (f)$ with $f$ regular (since $f$ is monic),
  we can find $K$   such that $L\cdot K = L\cap J$. Indeed, we have $(L\cap J)\cdot M \subseteq (f)$
  and so we can write $f K = (L\cap J)\cdot M$. We then have $f (L\cdot K) = (L\cap J)\cdot L\cdot M = f (L\cap J)$
  and so $L\cdot K = L\cap J$ since $f$ is monic.
  We then have $L\cdot K = 0$ modulo $J$ and hence $K = 0$ modulo $J$ since $L$ contains $f$
  which is monic.
  This means $L\cap J = L\cdot J$. Then we have $L = (h) + L\cdot J$.
  The result then follows from the fact that $h$ is monic and from Nakayama's Lemma, as in Lam \cite{Lam}:
  the module $P = L/(h)$ is a finitely generated module over $R$, since $f$ is monic, and satisfies
  $P\subseteq JP$ and $J$ is contained in the Jacobson radical of $R$, so $P = 0$ by Nakayama's Lemma.
\end{proof}

\begin{corollary}
  We can find comaximal elements $s_1,\dots,s_l$ such that $(u_1,\dots,u_n)$ is principal and generated by a
  monic polynomial in each $A_{s_j}[X]$. Since these monic polynomials are uniquely determined
  we can patch these generators and get that $(u_1,\dots,u_n)$ is principal in $A[X]$\footnote{If $A$ is not
  connected, the generator of $(u_1,\dots,u_n)$ may not be monic: if $e(1-e)=1$ then the ideal $(eX+(1-e))$
  divides the ideal $(X)$.}.
\end{corollary}

\newpage

\section*{Appendix 2: proof of Proposition \ref{units}}

The goal is to prove the following result.

\begin{proposition}\label{units}
  Let $A$ be a {\em connected} ring and let $t_{ij}$ be a family of  invertible elements in $T_{ij}(A)$ such that $t_{ii} = 1$
  and $t_{ij}t_{jk} = t_{ik}$. There exists an integer $N$ and $s_i$ invertible in $T_i$ such that $t_{ij} = (X_j/X_i)^Ns_j/s_i$ 
\end{proposition}

\begin{proof}
  %  (We follow essentially David's argument.)
  
%By \Cref{trivial}, a line bundle on $\bP^n$ is trivial on each $\Spec(T_l)$.
%So it is determined by $t_{ij}$ invertible in $T_i[X_i/X_j] = T_j[X_j/X_i] = T_{ij}$
%such that $t_{ik} = t_{ij}t_{jk}$ and $t_{ii} = 1$. 
Using \Cref{stand}, \Cref{nilpunit} and \Cref{connected}, we can assume without loss of generality, that
$t_{ij} = (X_i/X_j)^{N_{ij}} u_{ij}$, for some $N_{ij}$ in $\Z$, where $u_{ij}(p)$ is invertible for $p = 0$
and all other coefficients $u_{ij}(p)$ for $p\neq 0$
are nilpotent. By looking at the relation  $t_{ik} = t_{ij}t_{jk}$ when we quotient by nilpotent elements, we see that
$N_{ij} = N$ does not depend on $i,j$.

  Each $u_{ij}$ is such that $u_{ij}(p)$ unit for $p=0$ and
  all $u_{ij}(p)$ nilpotent for $p\neq 0$. The goal is to find $s_i$ unit in $T_i(A)$ such that
  $u_{ij} = s_j/s_i$.

  Let $M$ be the monoid of $p = (p_0,\dots,p_n)$ such that $p_0+\dots+p_n = 0$.
  Let $M_i$ be the submonoid of $p$ in $M$ such that $p_i<0$ and $p_l\geqslant 0$ if $l\neq i$
  and $M_{ij}$ the monoid of $p$ in $M$ such that $p_i<0$ and $p_j<0$ and $p_l\geqslant 0$ if $l\neq i,j$.
  We let $L_{i}$ be the free $A$-module generated by $X^p$ for $p$ in $M_i$ and $L_{ij}$ be the
  free $A$-module generated by $X^p$ for $p$ in $M_{ij}$. We can write $T_{i}(A)$ as the direct sum $A+L_i$
  and $T_{ij}(A)$ as the direct sum $A + L_i + L_j + L_{ij}$. Furthermore we have $L_iL_j\subseteq A + L_i + L_j + L_{ij}$
  and $L_iL_{ij}\subseteq L_i + L_{ij}$.

  The element $u_{01}$ can be uniquely decomposed as $u_{01} =  a + x + y + z$ with $a$ unit in $A$ and
  $x$ in $L_0$ and $y$ in $L_1$ and $z$ in $L_{01}$. We claim that we can assume $x = y = 0$ by multiplying
  $u_{01}$ by units in $T_0(A)$ and in $T_1(A)$.
  The argument is similar to the one of \Cref{nilpotent}. We let $J$ be the nilpotent ideal generated by all
  $u_{01}(p)$ for $p\neq 0$. We have $x$ in $JL_0$ and $y$ in $JL_1$ and $z$ in $JL_{01}$.
  We multiply $u_{01}$ by $1 - a^{-1}x$, getting
  $$(1-a^{-1}x) u_{01} = a' + x' + y' + z'$$
  with $a'$ unit in $A$ and $x'$ in $J^2L_0$ and $y'$ in $JL_1$ and $z'$ in $JL_{01}$.
  If we multiply by $1- a'^{-1}x'$ we get
  $$(1-a'^{-1}x') (a'+x'+y'+z') = a'' + x'' + y'' + z''$$
  with $a''$ unit in $A$ and $x''$ in $J^3L_0$ and $y''$ in $JL_1$ and $z''$ in $JL_{01}$.
  Keeping doing this, we see that there is a unit $u$ in $T_0(A)$ such that
  $uu_{01}$ is in $A + JL_1+ JL_{01}$. By a similar reasoning, and using that $L_1L_{01}\subseteq L_1 + L_{01}$, we find a unit
  $v$ in $T_1(A)$ such that $vuu_{01}$ is in $A + JL_{01}$.
  
  I claim now that if $u_{01}$ is in $A + L_{01}$ then $u_{01}$ is actually in $A$.

  For this, we use the relation $u_{01}= u_{0l}u_{l1}$, that is
  $$u_{01}(p) = u_{0l}(p)u_{l1}(0) + u_{0l}(0)u_{l1}(p) + \Sigma_{q+r = p, q\neq 0, r\neq 0}u_{0l}(q)u_{l1}(r)\leqno{(1)}$$

  \begin{lemma}
    For all $l\neq 0,1$, we have %$u_{0l}(p) = 0$ if $p$ is in $M_0$ and $u_{1l}(p) = 0$ if $p$ is in $M_1$.
    %It follows that
    $u_{0l}(p) = u_{1l}(p) = 0$ if $p_l>0$.
  \end{lemma}
  
  \begin{proof}
  We let $K$ be the ideal generated by coefficients $u_{0l}(p)$ 
  and $u_{l1}(p)$ for $p_l>0$ and $I$ the (nilpotent) ideal generated by all coefficients $u_{0l}(p)$ and
  $u_{l1}(p)$ for $p\neq 0$. %Using $(2)$, we show $K\subseteq KI$ and hence $K=0$ by Nakayama.
  We show $K\subseteq KI$.

  $(1)$ can be written as
  $$u_{0l}(p)u_{l1}(0) = u_{01}(p) - u_{0l}(0)u_{l1}(p) - \Sigma_{q+r = p, q\neq 0, r\neq 0}u_{0l}(q)u_{l1}(r)\leqno{(2)}$$
  (recall that $u_{l1}(0)$ is a unit). We use $(2)$ to show that $u_{0l}(p)$ is in $KI$ if $p_l>0$.

  The element $u_{0l}$ in $T_{0l}(A) = A+L_0+L_l+L_{0l}$, so we have $u_{0l}(p) = 0$ if $p$ is not in $M_0$ and $p_l>0$.
  So we can assume $p$ in $M_0$.

  We have $u_{01}(p) = 0$ if $p$ is in $M_0$, since $u_{01}$ is in $A+L_{01}$. We also have $u_{l1}(p) = 0$ if $p$ in $M_0$ since
  $u_{l1}$ is in $A+L_1+L_l+L_{1l}$.
  So, if $p$ is in $M_0$, we can rewrite $(2)$ as
  $$u_{0l}(p)u_{l1}(0) = - \Sigma_{q+r = p, q\neq 0, r\neq 0}u_{0l}(q)u_{l1}(r)$$
  Each member in the sum $u_{0l}(q)u_{l1}(r)$ is in $KI$ since $q_l+r_l = p_l>0$ and hence $q_l>0$ or $r_l>0$.
  So, we have $u_{0l}(p)$ in $KI$ if $p_l>0$.

  Similarly, using
  $$u_{0l}(0)u_{l1}(p) = u_{01}(p) - u_{0l}(p)u_{l1}(0) - \Sigma_{q+r = p, q\neq 0, r\neq 0}u_{0l}(q)u_{l1}(r)$$
  we show that $u_{l1}(p)$ is in $KI$ if $p_l>0$. So we have $K\subseteq KI$, as desired.

  We then deduce $K\subseteq KI^n$ for all $n$ and hence $K=0$ since $I$ is nilpotent.
  \end{proof}

  Let $p$ be in $M_{01}$. We can find $l\neq 0,1$ such that $p_l>0$. If $p = q+r$ we have $q_l>0$ or $r_l>0$ and hence
  by the Lemma, we have $u_{0l}(q) = 0$ or $u_{l1}(r) = 0$. Hence the equality $(1)$ shows that we have $u_{01}(p)= 0$.
  Since $u_{01}$ is in $A+L_{01}$, it follows that $u_{01}$ is actually a unit in $A$.

  W.l.o.g. we can assume $u_{01}= 1$. We then have $u_{0l} = u_{01}u_{1l} = u_{1l}$ in $T_{0l}(A)\cap T_{1l}(A) = T_l(A)$
  and we take $s_l = u_{0l} = u_{1l}$.
\end{proof}

Note that the proof is much simpler if $A$ is both connected {\em and} reduced (for example if $A$ is a discrete field).

Using Horrocks Theorem and the technique of Quillen patching, both explained in a constructive setting in \cite{lombardi-quitte}, we
obtain from this Proposition a constructive proof of the following purely algebraic result.

\begin{theorem}
  Let $A$ be a ring which is connected and such that $\Pic(A) = 0$. If $M_i$ is a projective module of rank $1$ over
  $T_i(A)$ and we have isomorphisms $t_{ij}:M_i\otimes T_{ij}(A) \equiv M_j\otimes T_{ij}(A)$ with $t_{ik} = t_{jk}\circ t_{ij}$
  and $t_{ii} = mathsf{id}$, then there is an integer $d$ and invertible elements $s_i$ in $T_i(A)$
  such that $t_{ij}$ and isomorphisms $\psi_i:M_i\equiv T_i(A)$ such that $\psi_j(t_{ij} x) = (X_j/X_i)^d s_j/s_i \psi_i(x)$ for all
  $x$ in $M_i\otimes T_{ij}(A)$.
\end{theorem}



\newpage


\section*{Appendix 3: Quillen Patching}

We reproduce the argument in Quillen's paper \cite{Quillen}, as simplified in \cite{lombardi-quitte}.
This technique of Quillen Patching has been replaced by the equivalence in Proposition \ref{Matthias}.

Let $P(X)$ be a presentation matrix of a finitely presented module $M$ over a ring $A[X]$. We say that $M$
is extended from $A$ if the matrix $P(X)$ and the matrix $P(0)$ presents isomorphic modules \cite{lombardi-quitte}, Ch. XVI.

 Quillen Patching can be presented as the following result.

\begin{theorem}\label{QP}
  If we have $M$ finitely presented of $A[X]$ and $f_1,\dots,f_n$ comaximal elements of $A$
  such that each $M\otimes_{A[X]} A[1/f_i][X]$ is extended from $A[1/f_i]$ then $M$ is extended from $A$.
\end{theorem}

Let us reformulate this result in the setting of Synthetic Algebraic Geometry \cite{draft}.
If $A$ is a finitely presented $R$-algebra, we know \cite{draft}, Theorem 7.2.3, that there is an
equivalence between $\fpMod{A[X]}$ and ${\fpMod{R}}^{\Spec(A)\times R}$, which to a module $M$
associates the family $M\otimes_{A[X]} (x,r)$ for $x:\Spec(A)$ and $r:R$. Conversely, to a family $L~x~r$
of finitely presented $R$-modules, we associate the finitely presented $A[X]$-module $\prod_{x:\Spec(A)}\prod_{r:R}L~x~r$.
We deduce from this the following characterisation of extended modules from $A$: the module corresponding to the
family $L~x~r$ is extended from $A$ if, and only if, we have $\prod_{x:\Spec(A)}\prod_{r:R}L~x~r = L~x~0$.

We can then reformulate Theorem \ref{QP} as follows.

\begin{corollary}
  If we have $f_1,\dots,f_n$ comaximal elements of $A$ and $\prod_{x:D(f_i)}\prod_{r:R}L~x~r = L~x~0$ for $i=1,\dots, n$
  then $\prod_{x:\Spec(A)}\prod_{x:R}L~x~r = L~x~0$.
\end{corollary}

It follows then from local choice that we have.

\begin{corollary}\label{QP1}
  If we have $\prod_{x:\Spec(A)}\norm{\prod_{r:R}L~x~r = L~x~0}$ then we have $\norm{\prod_{x:\Spec(A)}\prod_{x:R}L~x~r = L~x~0}$.
\end{corollary}

We can now compare Quillen's argument which uses Corollary \ref{Pic1} and Theorem \ref{QP}
instead of its refinement Corollary \ref{Matthias1}.

\begin{proposition}\label{trivial1}
  For all $V:\bP^n\rightarrow \KR$ we have $\norm{\prod_{s:R^n}V([1:s]) = V([0:1:0:\cdots :0])}$.
\end{proposition}

\begin{proof}
  We define $L:R^{n-1}\rightarrow (\bP^1 \to \KR)$ by $L~t~[x_0:x_1] = V([x_0:x_1:x_0t])$.
  Let $s=(s_1,\dots,s_{n}):R^{n}$. We apply Corollary \ref{Pic1} and we get, for all $s_2,\dots,s_n$
  \[
   \norm{V([1:s]) = L~(s_2,\dots,s_n)~[1:s_1] = L~(s_2,\dots,s_n)~[0:1]}
   \rlap{.}
   \]
   Using Corollary \ref{QP1}, we get $\norm{\prod_{s:R^n}V([1:s]) = V([0:1:0:\cdots :0])}$.
\end{proof}








If $P$ and $Q$ are two idempotent matrix of the same size, let us write $P\simeq Q$ for expressing that $P$ and $Q$ presents
the same projective module (which means that there are similar, which is in this case is the same as being equivalent).

If we have a projective module on $A[X]$, presented by a matrix $P(X)$, this module is extended
precisely when we have $P(X)\simeq P(0)$.

\begin{lemma}
  If $S$ is a multiplicative monoid of $A$ and $P(X)\simeq P(0)$ on $A_S[X]$ then there exists
  $s$ in $S$ such that $P(X+sY)\simeq P(X)$ in $A[X]$.
\end{lemma}

\begin{lemma}
  The set of $s$ in $A$ such that $P(X+sY)\simeq P(X)$ is an ideal of $A$.
\end{lemma}

\begin{corollary}
  If we have $M$ projective module of $A[X]$ and $S_1,\dots,S_n$ comaximal multiplicative monoids of $A$
  such that each $M\otimes_{A[X]} A_{S_i}[X]$ is extended from $A_{S_i}$ then $M$ is extended from $A$.
\end{corollary}

Let us reformulate in synthetic term this result. Let $A$ be a f.p. $R$-algebra and $L:\Spec(A)\rightarrow B\Gm^{\A^1}$.
Then $L$ corresponds to a projective module of rank $1$ on $A[X]$. We can form
$$T(x) = \prod_{r:R}L~x~r = L~x~0$$
and $\|T(x)\|$ expresses that $L~x$ defines a trivial line bundle on $\A^1 = \Spec(R[X])$.
It is extended exactly when we have
$\|{\prod_{x:\Spec(A)}T(x)}\|$. We can then use Zariski local choice to state.

\begin{proposition}\label{c2}
  We have the implication $(\prod_{x:\Spec(A)}\|T(x)\|)\rightarrow \|\prod_{x:\Spec(A)}T(x)\|$.
\end{proposition}

\newpage

\section*{Appendix 4: Classical argument}

We reproduce a message of Brian Conrad in MathOverflow \cite{conrad-mathoverflow-16324}.

\medskip

``We know that the Picard group of projective $(n-1)$-space over a field $k$ is $\Z$
generated by $\OO(1)$.
This underlies the proof that the automorphism group of such a projective space is $\PGL_n(k)$.
But what is the automorphism group of $\bP^{n-1}(A)$ for a general ring $A$? Is it $\PGL_n(A)$?
It's a really important fact that the answer is yes.
But how to prove it? It's a shame that this isn't done in Hartshorne.

By an elementary localization, we may assume $A$ is local.
In this case we claim that $\Pic(\bP^{n-1}(A))$ is infinite cyclic generated by $\OO(1)$.
Since this line bundle has the known $A$-module of global sections,
it would give the desired result if true by the same argument as in the field case.
And since we know the Picard group over the residue field, we can twist
to get to the case when the line bundle is trivial on the special fiber. How to do it?

\medskip

 Step 0: The case when $A$ is a field. Done.

 \medskip

 Step 1: The case when $A$ is Artin local.
 This goes via induction on the length, the case of length $0$ being Step $0$
 and the induction resting on cohomological results for projective space over the residue field.

  \medskip

 Step 2: The case when $A$ is complete local noetherian ring. This goes
 using Step 1 and the theorem on formal functions (formal schemes in disguise).

  \medskip

 Step 3: The case when $A$ is local noetherian.
 This is faithfully flat descent from Step 2 applied over $A~\widehat{}$

 \medskip
 
 Step 4: The case when $A$ is local:
 descent from the noetherian local case in Step 3 via direct limit arguments.

\medskip
 
QED''
